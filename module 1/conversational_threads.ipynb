{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many LLM applications have a chatbot-like interface in which the user and the LLM application engage in a multi-turn conversation. In order to track these conversations, you can use the Threads feature in LangSmith.\n",
    "\n",
    "This is relevant to our RAG application, which should maintain context from prior conversations with users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\"  # If you don't set this, traces will go to the Default project"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:50:17.522994Z",
     "start_time": "2025-10-04T14:50:17.516571Z"
    }
   },
   "source": [
    "# Or you can use a .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../../.env\", override=True)\n",
    "os.environ[\"USER_AGENT\"] = \"496\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group traces into threads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Thread is a sequence of traces representing a single conversation. Each response is represented as its own trace, but these traces are linked together by being part of the same thread.\n",
    "\n",
    "To associate traces together, you need to pass in a special metadata key where the value is the unique identifier for that thread.\n",
    "\n",
    "The key value is the unique identifier for that conversation. The key name should be one of:\n",
    "\n",
    "- session_id\n",
    "- thread_id\n",
    "- conversation_id.\n",
    "\n",
    "The value should be a UUID."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:50:18.387037Z",
     "start_time": "2025-10-04T14:50:18.381620Z"
    }
   },
   "source": [
    "import uuid\n",
    "thread_id = uuid.uuid4()\n",
    "print(f\"Thread ID: {thread_id}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread ID: 844a1f3e-cd19-40dd-a208-d350969e48af\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:50:44.320271Z",
     "start_time": "2025-10-04T14:50:19.930963Z"
    }
   },
   "source": [
    "from langsmith import traceable\n",
    "from anthropic import Anthropic\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "anthropic_client = Anthropic()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    rag_system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{rag_system_prompt}\\n\\nContext: {formatted_docs}\\n\\nQuestion: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return call_anthropic(messages)\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def call_anthropic(\n",
    "    messages: List[dict], model: str = \"claude-sonnet-4-5-20250929\", temperature: float = 0.0\n",
    ") -> str:\n",
    "    return anthropic_client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1024,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.content[0].text"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's run our application twice with this thread_id"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:50:51.088913Z",
     "start_time": "2025-10-04T14:50:46.522432Z"
    }
   },
   "source": [
    "question = \"How do I add metadata to a Trace?\"\n",
    "ai_answer = langsmith_rag(\n",
    "    question,\n",
    "    langsmith_extra={\"metadata\": {\"thread_id\": thread_id}}\n",
    ")\n",
    "print(ai_answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the documentation, you can add metadata to traces in LangSmith by passing a dictionary of key-value pairs along with your traces. Metadata is useful for storing additional information like the environment, user who initiated the trace, or internal correlation IDs. The documentation mentions that both Python and TypeScript support sending arbitrary metadata and tags with traces, though the specific code example wasn't fully shown in the provided context.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:51:00.879918Z",
     "start_time": "2025-10-04T14:50:54.027749Z"
    }
   },
   "source": [
    "question = \"How can I add tags to a Trace?\"\n",
    "ai_answer = langsmith_rag(\n",
    "    question,\n",
    "    langsmith_extra={\"metadata\": {\"thread_id\": thread_id}}\n",
    ")\n",
    "print(ai_answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the documentation, you can add tags to traces in LangSmith by sending them along with your traces during instrumentation. Tags are strings used to categorize or label a trace, and they're useful for associating additional information like the environment, user, or correlation ID. You can then filter and query traces based on these tags, such as filtering for runs where tags include \"experimental\" or \"beta\".\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look in LangSmith!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ls-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
